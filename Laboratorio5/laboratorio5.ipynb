{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4414cf41",
   "metadata": {},
   "source": [
    "importamos las bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "f6b5e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d311d9",
   "metadata": {},
   "source": [
    "creamos una clase modelo que herede el nn.modulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "d3599135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # capa de entrada que tiene 23 caracteristicas --> \n",
    "    # capa oculta1 con n neuronas  --> \n",
    "    # capa oculta2 con n neuronas --> \n",
    "    # capa de salida con 1 neurona y 2 clases de respuesta\n",
    "    def __init__(self, in_entradas=23, h1=30, h2=16, out_salidas=2):\n",
    "        super(Model, self).__init__()\n",
    "        # Definimos las capas lineales\n",
    "        self.fc1 = nn.Linear(in_entradas, h1)  # Capa de entrada a capa oculta 1\n",
    "        self.fc2 = nn.Linear(h1, h2)            # Capa oculta 1 a capa oculta 2\n",
    "        self.out = nn.Linear(h2, out_salidas)   # Capa oculta 2 a capa de salida\n",
    "\n",
    "    def adelante(self, x):\n",
    "        # función de activación ReLU para las capas ocultas\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # función de activación softmax para la capa de salida\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9964148",
   "metadata": {},
   "source": [
    "elegimos una semilla manualmente para poder elegir un numero aleatoriamente e instanciamos el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "d7dfe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5)  # Elegimos una semilla manualmente para poder elegir un numero aleatoriamente\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d948e3",
   "metadata": {},
   "source": [
    "importamos matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "b78c8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074bc73",
   "metadata": {},
   "source": [
    "importamos el dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "18da1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('clientes_sin_id.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "b55984a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>90000</th>\n",
       "      <th>2</th>\n",
       "      <th>2.1</th>\n",
       "      <th>2.2</th>\n",
       "      <th>34</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>...</th>\n",
       "      <th>14331</th>\n",
       "      <th>14948</th>\n",
       "      <th>15549</th>\n",
       "      <th>1518</th>\n",
       "      <th>1500</th>\n",
       "      <th>1000</th>\n",
       "      <th>1000.1</th>\n",
       "      <th>1000.2</th>\n",
       "      <th>5000</th>\n",
       "      <th>0.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19394</td>\n",
       "      <td>19619</td>\n",
       "      <td>20024</td>\n",
       "      <td>2500</td>\n",
       "      <td>1815</td>\n",
       "      <td>657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>542653</td>\n",
       "      <td>483003</td>\n",
       "      <td>473944</td>\n",
       "      <td>55000</td>\n",
       "      <td>40000</td>\n",
       "      <td>38000</td>\n",
       "      <td>20239</td>\n",
       "      <td>13750</td>\n",
       "      <td>13770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>-159</td>\n",
       "      <td>567</td>\n",
       "      <td>380</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>1687</td>\n",
       "      <td>1542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29992</th>\n",
       "      <td>220000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29993</th>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29997 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        90000  2  2.1  2.2  34  0  0.1  0.2  0.3  0.4  ...   14331   14948  \\\n",
       "0       50000  2    2    1  37  0    0    0    0    0  ...   28314   28959   \n",
       "1       50000  1    2    1  57 -1    0   -1    0    0  ...   20940   19146   \n",
       "2       50000  1    1    2  37  0    0    0    0    0  ...   19394   19619   \n",
       "3      500000  1    1    2  29  0    0    0    0    0  ...  542653  483003   \n",
       "4      100000  2    2    2  23  0   -1   -1    0    0  ...     221    -159   \n",
       "...       ... ..  ...  ...  .. ..  ...  ...  ...  ...  ...     ...     ...   \n",
       "29992  220000  1    3    1  39  0    0    0    0    0  ...   88004   31237   \n",
       "29993  150000  1    3    2  43 -1   -1   -1   -1    0  ...    8979    5190   \n",
       "29994   30000  1    2    2  37  4    3    2   -1    0  ...   20878   20582   \n",
       "29995   80000  1    3    1  41  1   -1    0    0    0  ...   52774   11855   \n",
       "29996   50000  1    2    1  46  0    0    0    0    0  ...   36535   32428   \n",
       "\n",
       "        15549   1518   1500   1000  1000.1  1000.2   5000  0.6  \n",
       "0       29547   2000   2019   1200    1100    1069   1000    0  \n",
       "1       19131   2000  36681  10000    9000     689    679    0  \n",
       "2       20024   2500   1815    657    1000    1000    800    0  \n",
       "3      473944  55000  40000  38000   20239   13750  13770    0  \n",
       "4         567    380    601      0     581    1687   1542    0  \n",
       "...       ...    ...    ...    ...     ...     ...    ...  ...  \n",
       "29992   15980   8500  20000   5003    3047    5000   1000    0  \n",
       "29993       0   1837   3526   8998     129       0      0    0  \n",
       "29994   19357      0      0  22000    4200    2000   3100    1  \n",
       "29995   48944  85900   3409   1178    1926   52964   1804    1  \n",
       "29996   15313   2078   1800   1430    1000    1000   1000    1  \n",
       "\n",
       "[29997 rows x 24 columns]"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#revisamos los datos\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "e55b4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = my_data.drop('0.6', axis=1)\n",
    "y = my_data['0.6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60be335",
   "metadata": {},
   "source": [
    "convertimos a arreglos de numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "fcbe7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "4b13f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "8f4771af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.005, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "ad7c605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertimos a tensores de pytorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "72ecd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "b08355bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fijar el criterio de perdida y cuan lejos estamos de la respuesta correcta\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "3318ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Loss: 0.5692400932312012\n",
      "Epoch 20/1000, Loss: 0.5341082215309143\n",
      "Epoch 30/1000, Loss: 0.5408948063850403\n",
      "Epoch 40/1000, Loss: 0.5291147232055664\n",
      "Epoch 50/1000, Loss: 0.5292728543281555\n",
      "Epoch 60/1000, Loss: 0.5285596251487732\n",
      "Epoch 70/1000, Loss: 0.5283145308494568\n",
      "Epoch 80/1000, Loss: 0.5282852649688721\n",
      "Epoch 90/1000, Loss: 0.5282403230667114\n",
      "Epoch 100/1000, Loss: 0.5282366275787354\n",
      "Epoch 110/1000, Loss: 0.5282324552536011\n",
      "Epoch 120/1000, Loss: 0.5282309055328369\n",
      "Epoch 130/1000, Loss: 0.5282309055328369\n",
      "Epoch 140/1000, Loss: 0.5282305479049683\n",
      "Epoch 150/1000, Loss: 0.528230607509613\n",
      "Epoch 160/1000, Loss: 0.5282304883003235\n",
      "Epoch 170/1000, Loss: 0.5282305479049683\n",
      "Epoch 180/1000, Loss: 0.5282304883003235\n",
      "Epoch 190/1000, Loss: 0.5282304883003235\n",
      "Epoch 200/1000, Loss: 0.5282304883003235\n",
      "Epoch 210/1000, Loss: 0.5282305479049683\n",
      "Epoch 220/1000, Loss: 0.5282304883003235\n",
      "Epoch 230/1000, Loss: 0.5282305479049683\n",
      "Epoch 240/1000, Loss: 0.5282303690910339\n",
      "Epoch 250/1000, Loss: 0.5282304286956787\n",
      "Epoch 260/1000, Loss: 0.5282304286956787\n",
      "Epoch 270/1000, Loss: 0.5282304286956787\n",
      "Epoch 280/1000, Loss: 0.5282305479049683\n",
      "Epoch 290/1000, Loss: 0.5282305479049683\n",
      "Epoch 300/1000, Loss: 0.5282304286956787\n",
      "Epoch 310/1000, Loss: 0.5282305479049683\n",
      "Epoch 320/1000, Loss: 0.5282305479049683\n",
      "Epoch 330/1000, Loss: 0.5282305479049683\n",
      "Epoch 340/1000, Loss: 0.5282305479049683\n",
      "Epoch 350/1000, Loss: 0.5282305479049683\n",
      "Epoch 360/1000, Loss: 0.5282305479049683\n",
      "Epoch 370/1000, Loss: 0.5282305479049683\n",
      "Epoch 380/1000, Loss: 0.5282305479049683\n",
      "Epoch 390/1000, Loss: 0.5282305479049683\n",
      "Epoch 400/1000, Loss: 0.5282305479049683\n",
      "Epoch 410/1000, Loss: 0.5282305479049683\n",
      "Epoch 420/1000, Loss: 0.5282305479049683\n",
      "Epoch 430/1000, Loss: 0.5282305479049683\n",
      "Epoch 440/1000, Loss: 0.5282305479049683\n",
      "Epoch 450/1000, Loss: 0.5282305479049683\n",
      "Epoch 460/1000, Loss: 0.5282305479049683\n",
      "Epoch 470/1000, Loss: 0.5282305479049683\n",
      "Epoch 480/1000, Loss: 0.5282305479049683\n",
      "Epoch 490/1000, Loss: 0.5282305479049683\n",
      "Epoch 500/1000, Loss: 0.5282305479049683\n",
      "Epoch 510/1000, Loss: 0.5282305479049683\n",
      "Epoch 520/1000, Loss: 0.5282305479049683\n",
      "Epoch 530/1000, Loss: 0.5282305479049683\n",
      "Epoch 540/1000, Loss: 0.5282305479049683\n",
      "Epoch 550/1000, Loss: 0.5282305479049683\n",
      "Epoch 560/1000, Loss: 0.5282305479049683\n",
      "Epoch 570/1000, Loss: 0.5282305479049683\n",
      "Epoch 580/1000, Loss: 0.5282305479049683\n",
      "Epoch 590/1000, Loss: 0.5282305479049683\n",
      "Epoch 600/1000, Loss: 0.5282305479049683\n",
      "Epoch 610/1000, Loss: 0.5282305479049683\n",
      "Epoch 620/1000, Loss: 0.5282305479049683\n",
      "Epoch 630/1000, Loss: 0.5282305479049683\n",
      "Epoch 640/1000, Loss: 0.5282305479049683\n",
      "Epoch 650/1000, Loss: 0.5282305479049683\n",
      "Epoch 660/1000, Loss: 0.5282305479049683\n",
      "Epoch 670/1000, Loss: 0.5282305479049683\n",
      "Epoch 680/1000, Loss: 0.5282305479049683\n",
      "Epoch 690/1000, Loss: 0.5282305479049683\n",
      "Epoch 700/1000, Loss: 0.5282305479049683\n",
      "Epoch 710/1000, Loss: 0.5282305479049683\n",
      "Epoch 720/1000, Loss: 0.5282305479049683\n",
      "Epoch 730/1000, Loss: 0.5282305479049683\n",
      "Epoch 740/1000, Loss: 0.5282305479049683\n",
      "Epoch 750/1000, Loss: 0.5282305479049683\n",
      "Epoch 760/1000, Loss: 0.5282305479049683\n",
      "Epoch 770/1000, Loss: 0.5282305479049683\n",
      "Epoch 780/1000, Loss: 0.5282305479049683\n",
      "Epoch 790/1000, Loss: 0.5282305479049683\n",
      "Epoch 800/1000, Loss: 0.5282305479049683\n",
      "Epoch 810/1000, Loss: 0.5282305479049683\n",
      "Epoch 820/1000, Loss: 0.5282305479049683\n",
      "Epoch 830/1000, Loss: 0.5282305479049683\n",
      "Epoch 840/1000, Loss: 0.5282305479049683\n",
      "Epoch 850/1000, Loss: 0.5282305479049683\n",
      "Epoch 860/1000, Loss: 0.5282305479049683\n",
      "Epoch 870/1000, Loss: 0.5282305479049683\n",
      "Epoch 880/1000, Loss: 0.5282305479049683\n",
      "Epoch 890/1000, Loss: 0.5282305479049683\n",
      "Epoch 900/1000, Loss: 0.5282305479049683\n",
      "Epoch 910/1000, Loss: 0.5282305479049683\n",
      "Epoch 920/1000, Loss: 0.5282305479049683\n",
      "Epoch 930/1000, Loss: 0.5282305479049683\n",
      "Epoch 940/1000, Loss: 0.5282305479049683\n",
      "Epoch 950/1000, Loss: 0.5282305479049683\n",
      "Epoch 960/1000, Loss: 0.5282305479049683\n",
      "Epoch 970/1000, Loss: 0.5282305479049683\n",
      "Epoch 980/1000, Loss: 0.5282305479049683\n",
      "Epoch 990/1000, Loss: 0.5282305479049683\n",
      "Epoch 1000/1000, Loss: 0.5282305479049683\n"
     ]
    }
   ],
   "source": [
    "#entrenamos el modelo \n",
    "epochs = 1000\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # pasamos los datos por el modelo\n",
    "    y_pred = model.adelante(X_train)\n",
    "\n",
    "    # Computamos y mostramos la pérdida\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.detach().numpy())\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f'Epoch {i+1}/{epochs}, Loss: {loss}')\n",
    "    # Hacemos el backward pass y optimizamos\n",
    "    optimizer.zero_grad()  # Zero gradients, else they will accumulate between epochs\n",
    "    loss.backward()        # Backpropagation, compute gradients\n",
    "    optimizer.step()       # actualizamos los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "464fd298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lo graficamos \n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss/error')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0140e98",
   "metadata": {},
   "source": [
    "evaluamos el modelo en el set de prueba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "e89a0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    #evaluamos el modelo en el set de prueba \n",
    "    y_eval = model.adelante(X_test)\n",
    "    loss = criterion(y_eval, y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "4ef12418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5353)"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "bb9189b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "2.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "3.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "4.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "5.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "6.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "7.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "8.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "9.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "10.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "11.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "12.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "13.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "14.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "15.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "16.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "17.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "18.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "19.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "20.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "21.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "22.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "23.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "24.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "25.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "26.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "27.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "28.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "29.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "30.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "31.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "32.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "33.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "34.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "35.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "36.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "37.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "38.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "39.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "40.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "41.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "42.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "43.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "44.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "45.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "46.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "47.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "48.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "49.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "50.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "51.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "52.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "53.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "54.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "55.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "56.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "57.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "58.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "59.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "60.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "61.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "62.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "63.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "64.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "65.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "66.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "67.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "68.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "69.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "70.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "71.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "72.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "73.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "74.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "75.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "76.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "77.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "78.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "79.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "80.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "81.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "82.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "83.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "84.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "85.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "86.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "87.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "88.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "89.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "90.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "91.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "92.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "93.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "94.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "95.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "96.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "97.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "98.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "99.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "100.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "101.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "102.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "103.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "104.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "105.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "106.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "107.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "108.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "109.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "110.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "111.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "112.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "113.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "114.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "115.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "116.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "117.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "118.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "119.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "120.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "121.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "122.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "123.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "124.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "125.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "126.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "127.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "128.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "129.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "130.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "131.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "132.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "133.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "134.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "135.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "136.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "137.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "138.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "139.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "140.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "141.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "142.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "143.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "144.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "145.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "146.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "147.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "148.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "149.) tensor([ 0.5742, -0.6853])\t \t  0\t 0\n",
      "150.) tensor([ 0.5742, -0.6853])\t \t  1\t 0\n",
      "El modelo tuvo 116 predicciones correctas de 150 lo cual nos da un 77.33333333333333% de efectividad\n"
     ]
    }
   ],
   "source": [
    "correctos = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.adelante(data)\n",
    "        \n",
    "        #nos va a decir la clase con mayor probabilidad\n",
    "        print(f'{i+1}.) {str(y_val)  }\\t \\t  {y_test[i]}\\t {y_val.argmax().item()}' )\n",
    "\n",
    "        #averiguamos si es correcto o no\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correctos += 1\n",
    "\n",
    "print(f'El modelo tuvo {correctos} predicciones correctas de {len(y_test)} lo cual nos da un {(correctos/len(y_test))*100}% de efectividad')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
